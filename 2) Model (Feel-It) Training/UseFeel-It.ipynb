{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniBorrelli/RetiGeografiche/blob/main/2)%20Model%20(Feel-It)%20Training/UseFeel-It.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSh7qUq18FrA"
      },
      "source": [
        "## HuggingFace Models\n",
        "\n",
        "You can find our HuggingFace models here:\n",
        "\n",
        "\n",
        "| Model                       | Download |\n",
        "| ------                      | -------------------------|\n",
        "| `feel-it-italian-sentiment` | [Link](https://huggingface.co/MilaNLProc/feel-it-italian-sentiment) |\n",
        "| `feel-it-italian-emotion`   | [Link](https://huggingface.co/MilaNLProc/feel-it-italian-emotion) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdhcJy8f75zp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install feel-it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLEabrOztWG1",
        "outputId": "96262ca6-3422-4160-eb5d-77cbef3271ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.11.3\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.3) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.3) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.3) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.3) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.3) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.3) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.3) (2.31.0)\n",
            "Collecting sacremoses (from transformers==4.11.3)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1 (from transformers==4.11.3)\n",
            "  Downloading tokenizers-0.10.3.tar.gz (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.3) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.11.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.11.3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.11.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.11.3) (2023.11.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.11.3) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.11.3) (1.3.2)\n",
            "Building wheels for collected packages: tokenizers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.11.3\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_qMhH7Z9kxH"
      },
      "source": [
        "### Emotion Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGcUOogd8SAw"
      },
      "outputs": [],
      "source": [
        "from feel_it import EmotionClassifier\n",
        "emotion_classifier = EmotionClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0eBzeI__E1",
        "outputId": "41e951d8-9d00-4a5a-b0b2-21398312aa5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['joy', 'anger', 'sadness', 'fear']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Controlla se Feel-It funziona correttamente\n",
        "emotion_classifier.predict([\"sono molto felice di questo risultato\",\n",
        "                            \"ma che cazzo vuoi\",\n",
        "                            \"che brutta cosa...mi stanno scendendo le lacrime...\",\n",
        "                            \"sì ok ma che spavento che mi sono preso\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-q2dtbSnk2j",
        "outputId": "81ae52c0-f25d-4e94-8d81-edb0effa0294"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29828/29828 [1:40:59<00:00,  4.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Il file con le emozioni e i sentimenti è stato salvato come 'output_con_emozioni_e_sentimenti.xlsx'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from feel_it import EmotionClassifier, SentimentClassifier\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Carica il file XLSX\n",
        "file_input = \"input.xlsx\"\n",
        "dataframe = pd.read_excel(file_input)\n",
        "\n",
        "# Inizializza gli oggetti EmotionClassifier e SentimentClassifier\n",
        "emotion_classifier = EmotionClassifier()\n",
        "sentiment_classifier = SentimentClassifier()\n",
        "\n",
        "# Funzione per predire emozioni e sentimenti per una lista di frasi\n",
        "def predici_emozioni_sentimenti(frase):\n",
        "    emozione = emotion_classifier.predict([frase])[0]\n",
        "    sentimento = sentiment_classifier.predict([frase])[0]\n",
        "    return emozione, sentimento\n",
        "\n",
        "# Utilizza il ThreadPoolExecutor per parallelizzare le predizioni\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    risultati = list(tqdm(executor.map(predici_emozioni_sentimenti, dataframe[\"Frase\"]), total=len(dataframe)))\n",
        "\n",
        "# Estrai le emozioni e i sentimenti dai risultati\n",
        "emozioni, sentimenti = zip(*risultati)\n",
        "\n",
        "# Aggiungi le colonne \"Emozione\" e \"Sentimento\" al DataFrame\n",
        "dataframe[\"Emozione\"] = emozioni\n",
        "dataframe[\"Sentimento\"] = sentimenti\n",
        "\n",
        "# Salva il DataFrame con le colonne aggiuntive in un nuovo file XLSX\n",
        "file_output = \"output_con_emozioni_e_sentimenti.xlsx\"\n",
        "dataframe.to_excel(file_output, index=False)\n",
        "print(f\"Il file con le emozioni e i sentimenti è stato salvato come '{file_output}'\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}